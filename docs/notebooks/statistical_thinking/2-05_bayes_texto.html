<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Probabilidad condicional, Naive Bayes y Clasificadores de Texto — 42:12 min &mdash; documentación de Cursos de Analítica y Machine Learning - </title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Cursos de Analítica y Machine Learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Asignaturas de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../redes_neuronales/index.html">Redes Neuronales Artificiales y Aprendizaje Profundo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fundamentos_de_analitica/index.html">Fundamentos de Analítica</a></li>
</ul>
<p class="caption"><span class="caption-text">Asignaturas de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ciencia_de_los_datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica_predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica_de_grandes_datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../productos_de_datos/index.html">Productos de Datos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Cursos de Analítica y Machine Learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Probabilidad condicional, Naive Bayes y Clasificadores de Texto — 42:12 min</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/notebooks/statistical_thinking/2-05_bayes_texto.ipynb.txt" rel="nofollow"> Ver código fuente de la página</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Probabilidad-condicional,-Naive-Bayes-y-Clasificadores-de-Texto-—-42:12-min">
<h1>Probabilidad condicional, Naive Bayes y Clasificadores de Texto — 42:12 min<a class="headerlink" href="#Probabilidad-condicional,-Naive-Bayes-y-Clasificadores-de-Texto-—-42:12-min" title="Enlazar permanentemente con este título"></a></h1>
<ul class="simple">
<li><p>40:12 min | Ultima modificación: Abril 5, 2021 | <a class="reference external" href="https://youtu.be/T4x6KNfOQek">YouTube</a></p></li>
</ul>
<p>Los <a class="reference external" href="https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo">clasificadores bayesianos ingenuos</a> son un tipo de clasificador probabilistico en el que se considera que cada característica de una instancia contribuye independientemente de las demás a que un objeto pertenezca a una clase determinada. Mientras que en la inducción de reglas de asociación (algoritmo 1R) solamente se considera una sola característica para determinar a que clase pertence una instancia, en un clasificador
ingenuo se consideran simultáneamente todas las características. En este tutorial se describen los fundamentos matemáticos en que se soporta este tipo de clasificadores y como se aplican a casos reales.</p>
<div class="section" id="Definición-del-problema">
<h2>Definición del problema<a class="headerlink" href="#Definición-del-problema" title="Enlazar permanentemente con este título"></a></h2>
<p>En este tutorial se aborda el problema de determinar si un mensaje de texto es válido o spam. Este es un problema típico de minería de texto. Desde el punto de vista del negocio, la recepción de publicidad no deseada y mensajes fraudulentos es un problema que afecta a muchos usuarios; y es por ello, que las compañias prestadoras de servicios desean filtrar este tipo de mensajes con el fin de evitar el consumo de espacio en su infraestructura y la molestia para el usuario.</p>
<p>Se tiene una muestra conformada por los siguientes mensajes:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> #  Tipo    Mensaje
---------------------------------------
 1  spam    w1 w3
 2  spam    w1 w2 w1 w3
 3  ham     w2 w4
 4  ham     w4 w5 w2
 5  ham     w2 w4 w2
</pre></div>
</div>
<p>El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítimo o spam, a partir del análisis de las palabras que contiente; se supone que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje.</p>
</div>
<div class="section" id="Conceptos-y-Definiciones-Básicas">
<h2>Conceptos y Definiciones Básicas<a class="headerlink" href="#Conceptos-y-Definiciones-Básicas" title="Enlazar permanentemente con este título"></a></h2>
<div class="section" id="Probabilidad">
<h3>Probabilidad<a class="headerlink" href="#Probabilidad" title="Enlazar permanentemente con este título"></a></h3>
<p>De los tutoriales anteriores, se sabe que si las variables <span class="math notranslate nohighlight">\(x_i\)</span> representan los eventos posibles, entonces:</p>
<ul class="simple">
<li><p>Todas las probabilidades deben estar entre <span class="math notranslate nohighlight">\(0\)</span> y <span class="math notranslate nohighlight">\(1\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[0 \le \text{Pr}(x_i) \le 1\]</div>
<ul class="simple">
<li><p>Las probabilidades de eventos mutuamente exclusivos (no pueden ocurrir simultáneamente) y colectivamente exhaustivos (cubren todo el universo de casos posibles) deben sumar la unidad:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n \text{Pr}(x_i) = 1\]</div>
<p>En las siguientes figuras, los eventos F1, F2 y F3, y V1 y V2 están definidos sobre el mismo universo; y son mutuamente exclusivos y colectivamente exhaustivos, tal que se cumplen las dos propiedades anteriores</p>
<p><img alt="assets/eventos-conjuntos-2.jpg" src="../../_images/eventos-conjuntos-2.jpg" /></p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F1) + \text{Pr}(F2) + \text{Pr}(F3) = 1, \quad \qquad \text{Pr}(V1) + \text{Pr}(V2) = 1\]</div>
</div>
<div class="section" id="Probabilidad-conjunta">
<h3>Probabilidad conjunta<a class="headerlink" href="#Probabilidad-conjunta" title="Enlazar permanentemente con este título"></a></h3>
<p>Los eventos considerados ocurren simultáneamente. En la siguiente figura, los eventos F1 y V2 ocurren simultáneamente (área sombreada de la figura), tal que su probabilidad conjunta es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F1~\text{and}~V2)\]</div>
<p><img alt="assets/probabilidad-conjunta-3.jpg" src="../../_images/probabilidad-conjunta-3.jpg" /></p>
</div>
<div class="section" id="Probabilidad-condicional">
<h3>Probabilidad condicional<a class="headerlink" href="#Probabilidad-condicional" title="Enlazar permanentemente con este título"></a></h3>
<p>Es la probabilidad de que ocurra un evento sabiendo que el otro ya ocurrio. En la siguiente figura el evento V2 es condicionar a la ocurrencia F1. Noté que en la siguiente figura, el universo no es el rectángulo anterior que cubre todos los eventos, si no el evento F1. De esta forma, la probabilidad condicional es sólo la proporción de V2 que se intercepta con F1, la cual corresponde a la porción sombreada de la figura de abajo. La siguiente expresión matemática permite calcular la probabilidad
condicional en términos de la probabilidad conjunta.</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(V2 \; | \; F1) = \text{Pr}(F1 \; \text{and} \; V2) \; / \; \text{Pr}(F1)\]</div>
<p>En otras palabras,</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; | \; B) * \text{Pr}(B) = \text{Pr}(A \; \text{and} \; B)\]</div>
<p>para dos eventos A y B.</p>
<p><img alt="assets/probabilidad-condicional.jpg" src="../../_images/probabilidad-condicional.jpg" /></p>
</div>
<div class="section" id="Independencia">
<h3>Independencia<a class="headerlink" href="#Independencia" title="Enlazar permanentemente con este título"></a></h3>
<p>Si los eventos <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span> son independientes, la probabilidad condicional del evento A dado que ocurrio el evento B es igual a la probabilidad del evento A:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; |  \; B) = \text{Pr}(A)\]</div>
<p>De la definición de probabilidad condicional:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A  \; |  \; B) = \text{Pr}(A) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(B)}\]</div>
<p>Entonces:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A\text{ and } B) \; =  \; \text{Pr}(A) \; * \; \text{Pr}(B)\]</div>
</div>
<div class="section" id="Probabilidad-marginal">
<h3>Probabilidad marginal<a class="headerlink" href="#Probabilidad-marginal" title="Enlazar permanentemente con este título"></a></h3>
<p>Sea <span class="math notranslate nohighlight">\(X_1\)</span> con <span class="math notranslate nohighlight">\(i = 1, ... , n\)</span> , un conjunto de eventos mutuamente exclusivos y colectivamente exhaustivos. La probabilidad de un evento <span class="math notranslate nohighlight">\(A\)</span> es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \sum_{i=1}^n \text{Pr}(A\text{ and }X_i)\]</div>
<p>En la siguiente figura se puede observar que para cualquiera de los tres eventos <span class="math notranslate nohighlight">\(F_j\)</span> (para <span class="math notranslate nohighlight">\(j=1,2,3\)</span>)</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F_j) = \text{Pr}(F_j\text{ and }V_1) + \text{Pr}(F_j\text{ and }V_2)\]</div>
<p>y que para los dos eventos <span class="math notranslate nohighlight">\(V_i\)</span> (<span class="math notranslate nohighlight">\(i=1,2\)</span>):</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(V_i) = \text{Pr}(V_i\text{ and }F_1) + \text{Pr}(V_i\text{ and }F_2) + \text{Pr}(V_i\text{ and }F_3)\]</div>
<p><img alt="assets/eventos-conjuntos.jpg" src="../../_images/eventos-conjuntos.jpg" /></p>
</div>
<div class="section" id="Unión-(OR)">
<h3>Unión (OR)<a class="headerlink" href="#Unión-(OR)" title="Enlazar permanentemente con este título"></a></h3>
<p>Para dos eventos <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \text{ or } B) = \text{Pr}(A) + \text{Pr}(B) - \text{Pr}(A\text{ and }B)\]</div>
<p>En la figura de abajo se observa que al unir las regiones de los eventos F1 y V2, las áreas se traslapan y por tanto hay que restar la intersección.</p>
<p><img alt="assets/probabilidad-conjunta.jpg" src="../../_images/probabilidad-conjunta-3.jpg" /></p>
</div>
<div class="section" id="Complemento-o-negación">
<h3>Complemento o negación<a class="headerlink" href="#Complemento-o-negación" title="Enlazar permanentemente con este título"></a></h3>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{not } A) = 1 - \text{Pr}(A)\]</div>
</div>
<div class="section" id="Probabilidad-total">
<h3>Probabilidad total<a class="headerlink" href="#Probabilidad-total" title="Enlazar permanentemente con este título"></a></h3>
<p>La probabilidad total indica que la probabilidad de un evento A puede calcularse como la probabilidad de que ocurran los eventos A y B simultáneamente más la probabilidad de que ocurran los evento A y <em>not</em> B (el complemento de B:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \text{Pr}(A\text{ and } B) + \text{Pr}(A\text{ and } \text{not }B)\]</div>
<p>Para la siguiente figura:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
\text{Pr}(V_2)
    &amp; = \text{Pr}(V_2 \text{ and } F_1) + \text{Pr}(V_2 \text{ and not } F_1) \\ \\
    &amp; = \text{Pr}(V_2 \text{ and } F_1) + \text{Pr}(V_2 \text{ and } (F_2 \cup F_3)) \\ \\
\end{split}\end{split}\]</div>
<p><img alt="assets/eventos-conjuntos.jpg" src="../../_images/eventos-conjuntos.jpg" /></p>
<p>La ecuación anterior puede expresarse en términos de probabilidades condicionales, tal que:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \text{Pr}(A \; | \; B) \; \text{Pr}(B)  \; + \;  \text{Pr}(A \; | \; \text{not }B)\text{ Pr}(\text{not }B)\]</div>
</div>
<div class="section" id="Teorema-de-Bayes">
<h3>Teorema de Bayes<a class="headerlink" href="#Teorema-de-Bayes" title="Enlazar permanentemente con este título"></a></h3>
<p>A partir de</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A  \; |  \; B) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(B)},
\quad
\text{Pr}(B  \; |  \; A) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(A)}\]</div>
<p>Se obtiene que:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; | \; B)\text{ Pr}({B}) =  \text{Pr}(B \; | \; A) \; \text{Pr}({A})\]</div>
<p>Despejando <span class="math notranslate nohighlight">\(\text{Pr}(B \; | \; A)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(B \; | \; A) =
    \frac{\text{Pr}(A \; | \; B) \; \text{Pr}(B)}{\text{Pr}(A)} =
    \frac{\text{Pr}(A \; | \; B)~\text{Pr}(B)} {\text{Pr}(A \; | \; B) \; \text{Pr}(B)  \; + \;  \text{Pr}(A \; | \; \text{not }B) \; \text{Pr}(\text{not }B)}\]</div>
<p>En la última ecuación, se aplica el teorema de probabilidad total para el evento A.</p>
<p><strong>Actividad.—</strong> Complete las siguientes tablas de probabilidades:</p>
<p><em>Probabilidades totales</em>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>          F1    F2    F3  Prob(V)
----------------------------------
    V1   0.10     ?  0.03       ?
    V2      ?  0.26  0.14    0.62
----------------------------------
 Prob(F)    ?     ?     ?
</pre></div>
</div>
<p><em>Probabilidades condicionales</em>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Prob(F|V)                 Prob(V|F)

        F1    F2    F3            F1    F2    F3
----------------------    ----------------------
  V1 10/38     ?     ?      V1     ? 25/51     ?
  V2     ?     ? 14/62      V2     ?     ?     ?
</pre></div>
</div>
<p><strong>Actividad.—</strong> Verifique las dos tablas de probabilidades condicionales calculadas en el ejercicio anterior usando el teorema de Bayes (es decir, calcule <code class="docutils literal notranslate"><span class="pre">Prob(V|F)</span></code> a partir de <code class="docutils literal notranslate"><span class="pre">Prob(F|V)</span></code> y viceversa).</p>
</div>
</div>
<div class="section" id="Aplicación-al-problema-propuesto">
<h2>Aplicación al problema propuesto<a class="headerlink" href="#Aplicación-al-problema-propuesto" title="Enlazar permanentemente con este título"></a></h2>
<p>En términos del problema de filtrado de mensajes de texto, V1 se interpreta como “Es spam” y V2 como NOT “Es spam”, ya que son eventos mutuamente exclusivos y colectivamente exhaustivos. Si F es la ocurrencia de una determinada palabra en el texto, como por ejemplo “Viagra”, entonces F1 sería “Viagra”(“viagra” aparece en el mensaje) y F2 sería NOT “Viagra” (“viagra” no aparece en el mensaje).</p>
<p>De acuerdo con el teorema de Bayes:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam} \; | \; \text{viagra}) = \frac{\text{Pr}(\text{viagra} \, | \,
\text{spam})*\text{Pr}(\text{spam})}{\text{Pr}(\text{viagra})}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{spam} \, | \, \text{viagra})\)</span> es la probabilidad posterior.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{viagra} \, | \, \text{spam})\)</span> es la verosimilitud.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{spam})\)</span> es la probabilidad prior, es decir, la probabilidad de que un mensaje sea spam sin conocer el texto que contiene.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{viagra})\)</span> es la verosimilitud marginal.</p></li>
</ul>
<p>El cálculo de cada una de las probabilidades se realiza tal como se hizo en el ejercicio anterior.</p>
<p>Para el caso analizado, se tiene una muestra de ejemplos de mensajes que han sido catalogados como spam y válidos (no spam):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> #  Tipo    Mensaje
---------------------------------------
 1  spam    w1 w3
 2  spam    w1 w2 w1 w3
 3  ham     w2 w4
 4  ham     w4 w5 w2
 5  ham     w2 w4 w2
</pre></div>
</div>
<p>Para realizar la clasificación se tienen cuatro palabras <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span>, <span class="math notranslate nohighlight">\(w_4\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span> que pueden estar o no en cada uno de los mensajes de texto. La probabilidad de que la palabra <span class="math notranslate nohighlight">\(w_1\)</span> este en el mensaje se nota como <span class="math notranslate nohighlight">\(\text{Pr}(w_1)\)</span>, y de que no este como <span class="math notranslate nohighlight">\(\text{Pr}(\text{not }w_1)\)</span>.</p>
<p><strong>Actividad.—</strong> Calcule las tablas de probabilidades:</p>
<p><strong>Probabilidad individual</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i)\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Evento          w1    w2    w3    w4    w5
------------------------------------------------
 Ocurre       3/14     ?     ?     ?   1/14
 No ocurre       ?     ?   12/14   ?     ?
</pre></div>
</div>
<p><strong>Probabilidad conjunta</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i, \text{Tipo})\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Tipo     w1    w2    w3    w4    w5  Pr(tipo)
----------------------------------------------
 spam   3/14     ?     ?     ?     ?     6/14
 ham       ?     ?  0/14     ?     ?        ?
</pre></div>
</div>
<p><strong>Probabilidad condicional</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
---------------------------------------------
spam    3/6     ?     ?     ?     ?
ham       ?     ?     ?   3/8     ?
</pre></div>
</div>
<p><strong>Probabilidad condicional</strong> <span class="math notranslate nohighlight">\(\text{Pr}(\text{not } w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
---------------------------------------------
spam      ?   5/6     ?     ?     ?
ham       ?     ?     ?     ?   7/8
</pre></div>
</div>
<p>A continuación se usará el teorema de Bayes para determine si el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> es spam. Ya que este mensaje contiene las palabras <span class="math notranslate nohighlight">\(w_1\)</span> y <span class="math notranslate nohighlight">\(w_4\)</span> y no contiene las palabras <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span>, la probabilidad de que sea spam es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>Por el teorema de Bayes, la ecuación anterior se transforma en:</p>
<div class="math notranslate nohighlight">
\[\frac{\text{Pr}(w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5 |~\text{spam}) * \text{Pr}(\text{spam})}
{\text{Pr}(~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)}\]</div>
<p>Si se tiene en cuenta que la ocurrencia de la palabras <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span>, <span class="math notranslate nohighlight">\(w_4\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span> son eventos independientes, es decir, que la ocurrencia de una palabra es independiente de la ocurrencia de las otras, entonces, el término <span class="math notranslate nohighlight">\(\text{Pr}(w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4 ~\text{and}~\text{not}~w_5|~\text{spam})\)</span> puede aproximarse como:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(w_1~|~\text{spam})*
\text{Pr}(\text{not}~w_2~|~\text{spam})*
\text{Pr}(\text{not}~w_3|~\text{spam})*
\text{Pr}(w_4~|~\text{spam})*
\text{Pr}(\text{not}~w_5|~\text{spam})\]</div>
<p>Estas cantidades ya fueron computadas en la actividad anterior.</p>
<p><strong>Actividad.—</strong> Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> sea spam, es decir, calcule la siguiente probabilidad:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p><strong>Actividad.—</strong> Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> sea ham, es decir, calcule la siguiente probabilidad:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{ham}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p><strong>Actividad.—</strong> Con base en los resultados anteriores, ¿El mensaje es ham o spam?</p>
<p>La ecuación</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(w_1~|~\text{spam})*
\text{Pr}(\text{not}~w_2~|~\text{spam})*
\text{Pr}(\text{not}~w_3|~\text{spam})*
\text{Pr}(w_4~|~\text{spam})*
\text{Pr}(\text{not}~w_5|~\text{spam})\]</div>
<p>es la usada en la implementación computacional del algoritmo Naive Bayes para el cómputo de las probabilidades posteriores. En general, la ecuación anterior se puede escribir como:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(C_L~|~F_1, ...,F_n) = \frac{1}{Z}\text{Pr}(C_L)\prod_{i=1}^n \text{Pr}(F_i~|~C_L)\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F_i\)</span> son las características (las <span class="math notranslate nohighlight">\(x_i\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(1/Z\)</span> es un factor de escala.</p></li>
<li><p><span class="math notranslate nohighlight">\(C_L\)</span> representa el nivel <span class="math notranslate nohighlight">\(L\)</span> de la clase <span class="math notranslate nohighlight">\(C\)</span>.</p></li>
</ul>
<p><strong>Estimador de Laplace</strong></p>
<p>Al construir la tabla de probabilidades de las ocurrencias de las palabras, es posible que una palabra <span class="math notranslate nohighlight">\(w_k\)</span> aparezca únicamente en los mensajes válidos y no aparezca en los mensajes spam. De esta forma si se calcula la probabilidad posterior de un nuevo mensaje que no la contiene, el resultado es cero para spam y uno para válido. Para prevernir esta situación, se hace que el conteo inicial no arranque en cero con el fin de que la probabilidad de ocurrencia sea siempre mayor que cero. Esto
equivale a tener un mensaje para cada clase conformado por todas las palabras posibles.</p>
<p><strong>Actividad.—</strong> Realice nuevamente el ejercicio anterior usando el estimador de Laplace.</p>
<p>Probabilidad individual <span class="math notranslate nohighlight">\(\text{Pr}(w_i)\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>                w1    w2    w3    w4    w5
----------------------------------------------
Ocurre        5/24     ?     ?     ?   3/24
No ocurre        ?     ?   20/24   ?     ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad conjunta:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5  Pr(tipo)
----------------------------------------------
spam   4/24     ?     ?     ?     ?    11/24
ham       ?     ?  1/24     ?     ?        ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad condicional <span class="math notranslate nohighlight">\(\text{Pr}(w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
----------------------------------------------
spam   4/11     ?     ?     ?   1/11
ham       ?     ?   1/13     ?    ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad condicional <span class="math notranslate nohighlight">\(\text{Pr}(\text{not } w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
----------------------------------------------
spam      ?  9/11     ?     ?     ?
ham       ?     ?     ?     ?  11/13
</pre></div>
</div>
<p>Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1w_4\)</span> sea spam:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>R/ 36.56%</p>
<p>Calcule la probabilidad de que el mensaje sea <span class="math notranslate nohighlight">\(w_1w_4\)</span> válido:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{ham}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>R/ 27.49%</p>
</div>
<div class="section" id="Implementación-de-la-solución-en-Python">
<h2>Implementación de la solución en Python<a class="headerlink" href="#Implementación-de-la-solución-en-Python" title="Enlazar permanentemente con este título"></a></h2>
<p>A continuación se presenta la solución usando el lenguaje Python.</p>
<div class="section" id="Creación-del-archivo">
<h3>Creación del archivo<a class="headerlink" href="#Creación-del-archivo" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> data.csv
<span class="n">texto</span><span class="p">,</span><span class="n">tipo</span>
<span class="n">ww1</span> <span class="n">ww3</span><span class="p">,</span><span class="n">spam</span>
<span class="n">ww1</span> <span class="n">ww2</span> <span class="n">ww1</span> <span class="n">ww3</span><span class="p">,</span><span class="n">spam</span>
<span class="n">ww2</span> <span class="n">ww4</span><span class="p">,</span><span class="n">ham</span>
<span class="n">ww4</span> <span class="n">ww5</span> <span class="n">ww2</span><span class="p">,</span><span class="n">ham</span>
<span class="n">ww2</span> <span class="n">ww4</span> <span class="n">ww2</span><span class="p">,</span><span class="n">ham</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing data.csv
</pre></div></div>
</div>
</div>
<div class="section" id="Lectura-de-datos">
<h3>Lectura de datos<a class="headerlink" href="#Lectura-de-datos" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;data.csv&quot;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span>         <span class="c1"># separador de campos</span>
    <span class="n">thousands</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># separador de miles para números</span>
    <span class="n">decimal</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span>     <span class="c1"># separador de los decimales para números</span>
<span class="p">)</span>

<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texto</th>
      <th>tipo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ww1 ww3</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ww1 ww2 ww1 ww3</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ww2 ww4</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ww4 ww5 ww2</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ww2 ww4 ww2</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se preparan los datos. El conjunto de</span>
<span class="c1"># datos es una lista de strings donde cada</span>
<span class="c1"># string es un mensaje</span>
<span class="c1">#</span>
<span class="n">df</span><span class="o">.</span><span class="n">texto</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0            ww1 ww3
1    ww1 ww2 ww1 ww3
2            ww2 ww4
3        ww4 ww5 ww2
4        ww2 ww4 ww2
Name: texto, dtype: object
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># La clase a la que pertenece cada mensaje</span>
<span class="c1"># también se representa como una lista de strings</span>
<span class="c1">#</span>
<span class="n">df</span><span class="o">.</span><span class="n">tipo</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    spam
1    spam
2     ham
3     ham
4     ham
Name: tipo, dtype: object
</pre></div></div>
</div>
</div>
<div class="section" id="Transformación">
<h3>Transformación<a class="headerlink" href="#Transformación" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se importa la librería</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1">#</span>
<span class="c1"># La representación DocumentTermMatrix corresponde a</span>
<span class="c1"># a una matriz en la que cada fila corresponde</span>
<span class="c1"># a un mensaje y cada columna es una palabra.</span>
<span class="c1">#</span>
<span class="c1">#        | ww1 ww2 ww3 ww4 ww5</span>
<span class="c1">#  -----------------------------</span>
<span class="c1">#  msg 0 |   1   0   1   0   0</span>
<span class="c1">#      1 |   2   1   1   0   0</span>
<span class="c1">#      2 |   0   1   0   1   0</span>
<span class="c1">#      3 |   0   1   0   1   1</span>
<span class="c1">#      4 |   0   2   0   1   0</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># A continuación se crea un transformador</span>
<span class="c1">#</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;content&quot;</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Se aplica el transformador al texto para convertirlo</span>
<span class="c1"># a DTM.</span>
<span class="c1">#</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">texto</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># También se genera una variable para el tipo</span>
<span class="c1">#</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">tipo</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se imprimen los nombres de las columnas</span>
<span class="c1">##</span>
<span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;ww1&#39;, &#39;ww2&#39;, &#39;ww3&#39;, &#39;ww4&#39;, &#39;ww5&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se imprime la matriz de términos y documentos</span>
<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 0 1 0 0]
 [2 1 1 0 0]
 [0 1 0 1 0]
 [0 1 0 1 1]
 [0 2 0 1 0]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Ya que lo que interesa es la presencia o no de la palabra</span>
<span class="c1"># y no interesa la cantidad de veces que aparece, entonces</span>
<span class="c1"># se aplica una transformación a la matriz</span>
<span class="c1">#</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">element</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">()]</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1, 0, 1, 0, 0],
 [1, 1, 1, 0, 0],
 [0, 1, 0, 1, 0],
 [0, 1, 0, 1, 1],
 [0, 1, 0, 1, 0]]
</pre></div></div>
</div>
</div>
<div class="section" id="Especificación-del-modelo">
<h3>Especificación del modelo<a class="headerlink" href="#Especificación-del-modelo" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se importa la libreria</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>

<span class="c1">#</span>
<span class="c1"># Se crea un clasificador Gaussiano ingenuo</span>
<span class="c1">#</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">(</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>        <span class="c1"># Laplace parameter</span>
    <span class="n">binarize</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">fit_prior</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_prior</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Entrenamiento">
<h3>Entrenamiento<a class="headerlink" href="#Entrenamiento" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se entrena el clasificador</span>
<span class="c1">#</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)
</pre></div></div>
</div>
</div>
<div class="section" id="Pronóstico">
<h3>Pronóstico<a class="headerlink" href="#Pronóstico" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se pronostica la clasificación de los</span>
<span class="c1"># mensajes para los datos de entrada</span>
<span class="c1">#</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;predicted&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texto</th>
      <th>tipo</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ww1 ww3</td>
      <td>spam</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ww1 ww2 ww1 ww3</td>
      <td>spam</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ww2 ww4</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ww4 ww5 ww2</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ww2 ww4 ww2</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<hr class="docutils" />
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>rm data.csv
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2019-2021, Juan D. Velasquez.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXX-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-XXXXXXX-1', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>