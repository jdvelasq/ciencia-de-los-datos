<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Copyright 2020 The TensorFlow Authors. &mdash; documentación de Cursos de Analítica y Machine Learning - </title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Cursos de Analítica y Machine Learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Asignaturas de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../redes_neuronales/index.html">Redes Neuronales Artificiales y Aprendizaje Profundo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fundamentos_de_analitica/index.html">Fundamentos de Analítica</a></li>
</ul>
<p class="caption"><span class="caption-text">Asignaturas de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../analitica_descriptiva/index.html">Analítica descriptiva y visualización de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ciencia_de_los_datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica_predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica_de_grandes_datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../productos_de_datos/index.html">Productos de Datos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Cursos de Analítica y Machine Learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Copyright 2020 The TensorFlow Authors.</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/notebooks/tensorflow_10_generative/1-07_autoencoder.ipynb.txt" rel="nofollow"> Ver código fuente de la página</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2020-The-TensorFlow-Authors.">
<h1>Copyright 2020 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2020-The-TensorFlow-Authors." title="Enlazar permanentemente con este título"></a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Intro-to-Autoencoders">
<h2>Intro to Autoencoders<a class="headerlink" href="#Intro-to-Autoencoders" title="Enlazar permanentemente con este título"></a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><img alt="c7395f67895b443aaf782e9feb64c680" src="https://www.tensorflow.org/images/tf_logo_32px.png" /> View on TensorFlow.org</p>
</td><td><p><img alt="e5772655ee814b04a7f83333eec4d6c8" src="https://www.tensorflow.org/images/colab_logo_32px.png" /> Run in Google Colab</p>
</td><td><p><img alt="4bbf8eaabe8a499abd47e2099b667e88" src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" /> View source on GitHub</p>
</td><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>19e8dd171ca6443b8baca9644b76bc8e|Download notebook</p>
</td></table><p>This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection.</p>
<p>An autoencoder is a special type of neural network that is trained to copy its input to its output. For example, given an image of a handwritten digit, an autoencoder first encodes the image into a lower dimensional latent representation, then decodes the latent representation back to an image. An autoencoder learns to compress the data while minimizing the reconstruction error.</p>
<p>To learn more about autoencoders, please consider reading chapter 14 from <a class="reference external" href="https://www.deeplearningbook.org/">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.</p>
<div class="section" id="Import-TensorFlow-and-other-libraries">
<h3>Import TensorFlow and other libraries<a class="headerlink" href="#Import-TensorFlow-and-other-libraries" title="Enlazar permanentemente con este título"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, losses
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Model
</pre></div>
</div>
</div>
</div>
<div class="section" id="Load-the-dataset">
<h3>Load the dataset<a class="headerlink" href="#Load-the-dataset" title="Enlazar permanentemente con este título"></a></h3>
<p>To start, you will train the basic autoencoder using the Fashion MNIST dataset. Each image in this dataset is 28x28 pixels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(x_train, _), (x_test, _) = fashion_mnist.load_data()

x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.

print (x_train.shape)
print (x_test.shape)
</pre></div>
</div>
</div>
</div>
<div class="section" id="First-example:-Basic-autoencoder">
<h3>First example: Basic autoencoder<a class="headerlink" href="#First-example:-Basic-autoencoder" title="Enlazar permanentemente con este título"></a></h3>
<p><img alt="Basic autoencoder results" src="../../_images/intro_autoencoder_result.png" /></p>
<p>Define an autoencoder with two Dense layers: an <code class="docutils literal notranslate"><span class="pre">encoder</span></code>, which compresses the images into a 64 dimensional latent vector, and a <code class="docutils literal notranslate"><span class="pre">decoder</span></code>, that reconstructs the original image from the latent space.</p>
<p>To define your model, use the <a class="reference external" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Keras Model Subclassing API</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>latent_dim = 64

class Autoencoder(Model):
  def __init__(self, latent_dim):
    super(Autoencoder, self).__init__()
    self.latent_dim = latent_dim
    self.encoder = tf.keras.Sequential([
      layers.Flatten(),
      layers.Dense(latent_dim, activation=&#39;relu&#39;),
    ])
    self.decoder = tf.keras.Sequential([
      layers.Dense(784, activation=&#39;sigmoid&#39;),
      layers.Reshape((28, 28))
    ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Autoencoder(latent_dim)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.compile(optimizer=&#39;adam&#39;, loss=losses.MeanSquaredError())
</pre></div>
</div>
</div>
<p>Train the model using <code class="docutils literal notranslate"><span class="pre">x_train</span></code> as both the input and the target. The <code class="docutils literal notranslate"><span class="pre">encoder</span></code> will learn to compress the dataset from 784 dimensions to the latent space, and the <code class="docutils literal notranslate"><span class="pre">decoder</span></code> will learn to reconstruct the original images. .</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.fit(x_train, x_train,
                epochs=10,
                shuffle=True,
                validation_data=(x_test, x_test))
</pre></div>
</div>
</div>
<p>Now that the model is trained, let’s test it by encoding and decoding images from the test set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>encoded_imgs = autoencoder.encoder(x_test).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
  # display original
  ax = plt.subplot(2, n, i + 1)
  plt.imshow(x_test[i])
  plt.title(&quot;original&quot;)
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # display reconstruction
  ax = plt.subplot(2, n, i + 1 + n)
  plt.imshow(decoded_imgs[i])
  plt.title(&quot;reconstructed&quot;)
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
plt.show()
</pre></div>
</div>
</div>
</div>
<div class="section" id="Second-example:-Image-denoising">
<h3>Second example: Image denoising<a class="headerlink" href="#Second-example:-Image-denoising" title="Enlazar permanentemente con este título"></a></h3>
<p><img alt="Image denoising results" src="../../_images/image_denoise_fmnist_results.png" /></p>
<p>An autoencoder can also be trained to remove noise from images. In the following section, you will create a noisy version of the Fashion MNIST dataset by applying random noise to each image. You will then train an autoencoder using the noisy image as input, and the original image as the target.</p>
<p>Let’s reimport the dataset to omit the modifications made earlier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(x_train, _), (x_test, _) = fashion_mnist.load_data()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.

x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

print(x_train.shape)
</pre></div>
</div>
</div>
<p>Adding random noise to the images</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>noise_factor = 0.2
x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)
x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)

x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)
x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)
</pre></div>
</div>
</div>
<p>Plot the noisy images.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>n = 10
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i + 1)
    plt.title(&quot;original + noise&quot;)
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
plt.show()
</pre></div>
</div>
</div>
<div class="section" id="Define-a-convolutional-autoencoder">
<h4>Define a convolutional autoencoder<a class="headerlink" href="#Define-a-convolutional-autoencoder" title="Enlazar permanentemente con este título"></a></h4>
<p>In this example, you will train a convolutional autoencoder using <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D">Conv2D</a> layers in the <code class="docutils literal notranslate"><span class="pre">encoder</span></code>, and <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose">Conv2DTranspose</a> layers in the <code class="docutils literal notranslate"><span class="pre">decoder</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class Denoise(Model):
  def __init__(self):
    super(Denoise, self).__init__()
    self.encoder = tf.keras.Sequential([
      layers.Input(shape=(28, 28, 1)),
      layers.Conv2D(16, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, strides=2),
      layers.Conv2D(8, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, strides=2)])

    self.decoder = tf.keras.Sequential([
      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation=&#39;relu&#39;, padding=&#39;same&#39;),
      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation=&#39;relu&#39;, padding=&#39;same&#39;),
      layers.Conv2D(1, kernel_size=(3, 3), activation=&#39;sigmoid&#39;, padding=&#39;same&#39;)])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Denoise()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.compile(optimizer=&#39;adam&#39;, loss=losses.MeanSquaredError())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.fit(x_train_noisy, x_train,
                epochs=10,
                shuffle=True,
                validation_data=(x_test_noisy, x_test))
</pre></div>
</div>
</div>
<p>Let’s take a look at a summary of the encoder. Notice how the images are downsampled from 28x28 to 7x7.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.encoder.summary()
</pre></div>
</div>
</div>
<p>The decoder upsamples the images back from 7x7 to 28x28.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.decoder.summary()
</pre></div>
</div>
</div>
<p>Plotting both the noisy images and the denoised images produced by the autoencoder.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>encoded_imgs = autoencoder.encoder(x_test).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # display original + noise
    ax = plt.subplot(2, n, i + 1)
    plt.title(&quot;original + noise&quot;)
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    bx = plt.subplot(2, n, i + n + 1)
    plt.title(&quot;reconstructed&quot;)
    plt.imshow(tf.squeeze(decoded_imgs[i]))
    plt.gray()
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
plt.show()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Third-example:-Anomaly-detection">
<h3>Third example: Anomaly detection<a class="headerlink" href="#Third-example:-Anomaly-detection" title="Enlazar permanentemente con este título"></a></h3>
</div>
<div class="section" id="Overview">
<h3>Overview<a class="headerlink" href="#Overview" title="Enlazar permanentemente con este título"></a></h3>
<p>In this example, you will train an autoencoder to detect anomalies on the <a class="reference external" href="http://www.timeseriesclassification.com/description.php?Dataset=ECG5000">ECG5000 dataset</a>. This dataset contains 5,000 <a class="reference external" href="https://en.wikipedia.org/wiki/Electrocardiography">Electrocardiograms</a>, each with 140 data points. You will use a simplified version of the dataset, where each example has been labeled either <code class="docutils literal notranslate"><span class="pre">0</span></code> (corresponding to an abnormal rhythm), or <code class="docutils literal notranslate"><span class="pre">1</span></code> (corresponding to a normal rhythm). You are
interested in identifying the abnormal rhythms.</p>
<p>Note: This is a labeled dataset, so you could phrase this as a supervised learning problem. The goal of this example is to illustrate anomaly detection concepts you can apply to larger datasets, where you do not have labels available (for example, if you had many thousands of normal rhythms, and only a small number of abnormal rhythms).</p>
<p>How will you detect anomalies using an autoencoder? Recall that an autoencoder is trained to minimize reconstruction error. You will train an autoencoder on the normal rhythms only, then use it to reconstruct all the data. Our hypothesis is that the abnormal rhythms will have higher reconstruction error. You will then classify a rhythm as an anomaly if the reconstruction error surpasses a fixed threshold.</p>
<div class="section" id="Load-ECG-data">
<h4>Load ECG data<a class="headerlink" href="#Load-ECG-data" title="Enlazar permanentemente con este título"></a></h4>
<p>The dataset you will use is based on one from <a class="reference external" href="http://www.timeseriesclassification.com/description.php?Dataset=ECG5000">timeseriesclassification.com</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Download the dataset
dataframe = pd.read_csv(&#39;http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv&#39;, header=None)
raw_data = dataframe.values
dataframe.head()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># The last element contains the labels
labels = raw_data[:, -1]

# The other data points are the electrocadriogram data
data = raw_data[:, 0:-1]

train_data, test_data, train_labels, test_labels = train_test_split(
    data, labels, test_size=0.2, random_state=21
)
</pre></div>
</div>
</div>
<p>Normalize the data to <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>min_val = tf.reduce_min(train_data)
max_val = tf.reduce_max(train_data)

train_data = (train_data - min_val) / (max_val - min_val)
test_data = (test_data - min_val) / (max_val - min_val)

train_data = tf.cast(train_data, tf.float32)
test_data = tf.cast(test_data, tf.float32)
</pre></div>
</div>
</div>
<p>You will train the autoencoder using only the normal rhythms, which are labeled in this dataset as <code class="docutils literal notranslate"><span class="pre">1</span></code>. Separate the normal rhythms from the abnormal rhythms.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train_labels = train_labels.astype(bool)
test_labels = test_labels.astype(bool)

normal_train_data = train_data[train_labels]
normal_test_data = test_data[test_labels]

anomalous_train_data = train_data[~train_labels]
anomalous_test_data = test_data[~test_labels]
</pre></div>
</div>
</div>
<p>Plot a normal ECG.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>plt.grid()
plt.plot(np.arange(140), normal_train_data[0])
plt.title(&quot;A Normal ECG&quot;)
plt.show()
</pre></div>
</div>
</div>
<p>Plot an anomalous ECG.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>plt.grid()
plt.plot(np.arange(140), anomalous_train_data[0])
plt.title(&quot;An Anomalous ECG&quot;)
plt.show()
</pre></div>
</div>
</div>
</div>
<div class="section" id="Build-the-model">
<h4>Build the model<a class="headerlink" href="#Build-the-model" title="Enlazar permanentemente con este título"></a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class AnomalyDetector(Model):
  def __init__(self):
    super(AnomalyDetector, self).__init__()
    self.encoder = tf.keras.Sequential([
      layers.Dense(32, activation=&quot;relu&quot;),
      layers.Dense(16, activation=&quot;relu&quot;),
      layers.Dense(8, activation=&quot;relu&quot;)])

    self.decoder = tf.keras.Sequential([
      layers.Dense(16, activation=&quot;relu&quot;),
      layers.Dense(32, activation=&quot;relu&quot;),
      layers.Dense(140, activation=&quot;sigmoid&quot;)])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = AnomalyDetector()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;mae&#39;)
</pre></div>
</div>
</div>
<p>Notice that the autoencoder is trained using only the normal ECGs, but is evaluated using the full test set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>history = autoencoder.fit(normal_train_data, normal_train_data,
          epochs=20,
          batch_size=512,
          validation_data=(test_data, test_data),
          shuffle=True)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>plt.plot(history.history[&quot;loss&quot;], label=&quot;Training Loss&quot;)
plt.plot(history.history[&quot;val_loss&quot;], label=&quot;Validation Loss&quot;)
plt.legend()
</pre></div>
</div>
</div>
<p>You will soon classify an ECG as anomalous if the reconstruction error is greater than one standard deviation from the normal training examples. First, let’s plot a normal ECG from the training set, the reconstruction after it’s encoded and decoded by the autoencoder, and the reconstruction error.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>encoded_data = autoencoder.encoder(normal_test_data).numpy()
decoded_data = autoencoder.decoder(encoded_data).numpy()

plt.plot(normal_test_data[0], &#39;b&#39;)
plt.plot(decoded_data[0], &#39;r&#39;)
plt.fill_between(np.arange(140), decoded_data[0], normal_test_data[0], color=&#39;lightcoral&#39;)
plt.legend(labels=[&quot;Input&quot;, &quot;Reconstruction&quot;, &quot;Error&quot;])
plt.show()
</pre></div>
</div>
</div>
<p>Create a similar plot, this time for an anomalous test example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>encoded_data = autoencoder.encoder(anomalous_test_data).numpy()
decoded_data = autoencoder.decoder(encoded_data).numpy()

plt.plot(anomalous_test_data[0], &#39;b&#39;)
plt.plot(decoded_data[0], &#39;r&#39;)
plt.fill_between(np.arange(140), decoded_data[0], anomalous_test_data[0], color=&#39;lightcoral&#39;)
plt.legend(labels=[&quot;Input&quot;, &quot;Reconstruction&quot;, &quot;Error&quot;])
plt.show()
</pre></div>
</div>
</div>
</div>
<div class="section" id="Detect-anomalies">
<h4>Detect anomalies<a class="headerlink" href="#Detect-anomalies" title="Enlazar permanentemente con este título"></a></h4>
<p>Detect anomalies by calculating whether the reconstruction loss is greater than a fixed threshold. In this tutorial, you will calculate the mean average error for normal examples from the training set, then classify future examples as anomalous if the reconstruction error is higher than one standard deviation from the training set.</p>
<p>Plot the reconstruction error on normal ECGs from the training set</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>reconstructions = autoencoder.predict(normal_train_data)
train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)

plt.hist(train_loss[None,:], bins=50)
plt.xlabel(&quot;Train loss&quot;)
plt.ylabel(&quot;No of examples&quot;)
plt.show()
</pre></div>
</div>
</div>
<p>Choose a threshold value that is one standard deviations above the mean.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>threshold = np.mean(train_loss) + np.std(train_loss)
print(&quot;Threshold: &quot;, threshold)
</pre></div>
</div>
</div>
<p>Note: There are other strategies you could use to select a threshold value above which test examples should be classified as anomalous, the correct approach will depend on your dataset. You can learn more with the links at the end of this tutorial.</p>
<p>If you examine the reconstruction error for the anomalous examples in the test set, you’ll notice most have greater reconstruction error than the threshold. By varing the threshold, you can adjust the <a class="reference external" href="https://developers.google.com/machine-learning/glossary#precision">precision</a> and <a class="reference external" href="https://developers.google.com/machine-learning/glossary#recall">recall</a> of your classifier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>reconstructions = autoencoder.predict(anomalous_test_data)
test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)

plt.hist(test_loss[None, :], bins=50)
plt.xlabel(&quot;Test loss&quot;)
plt.ylabel(&quot;No of examples&quot;)
plt.show()
</pre></div>
</div>
</div>
<p>Classify an ECG as an anomaly if the reconstruction error is greater than the threshold.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def predict(model, data, threshold):
  reconstructions = model(data)
  loss = tf.keras.losses.mae(reconstructions, data)
  return tf.math.less(loss, threshold)

def print_stats(predictions, labels):
  print(&quot;Accuracy = {}&quot;.format(accuracy_score(labels, predictions)))
  print(&quot;Precision = {}&quot;.format(precision_score(labels, predictions)))
  print(&quot;Recall = {}&quot;.format(recall_score(labels, predictions)))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>preds = predict(autoencoder, test_data, threshold)
print_stats(preds, test_labels)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Next-steps">
<h3>Next steps<a class="headerlink" href="#Next-steps" title="Enlazar permanentemente con este título"></a></h3>
<p>To learn more about anomaly detection with autoencoders, check out this excellent <a class="reference external" href="https://anomagram.fastforwardlabs.com/#/">interactive example</a> built with TensorFlow.js by Victor Dibia. For a real-world use case, you can learn how <a class="reference external" href="https://blog.tensorflow.org/2020/04/how-airbus-detects-anomalies-iss-telemetry-data-tfx.html">Airbus Detects Anomalies in ISS Telemetry Data</a> using TensorFlow. To learn more about the basics, consider reading this <a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html">blog
post</a> by François Chollet. For more details, check out chapter 14 from <a class="reference external" href="https://www.deeplearningbook.org/">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2019-2021, Juan D. Velasquez.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXX-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-XXXXXXX-1', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>